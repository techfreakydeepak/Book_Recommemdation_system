{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfIeOhhD+RDPRvIfg4CSbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techfreakydeepak/Book_Recommemdation_system/blob/main/Books_Recomadition_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "54LndQlWa3_3"
      },
      "outputs": [],
      "source": [
        "#Importing modules\n",
        "import pandas as pd\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "# This is to supress the warning messages (if any) generated in our code\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M5VNU3WzbDKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#file_path = ('/content/drive/MyDrive/Book_recommendation_system')\n",
        "#users = pd.read_csv(file_path)\n",
        "#users.head()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Book_recommendation_system/Users.csv'\n",
        "users = pd.read_csv(file_path)\n",
        "users.head()"
      ],
      "metadata": {
        "id": "cEI_3EFQbRpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books data\n",
        "file_path = ('/content/drive/MyDrive/Book_recommendation_system/Books.csv')\n",
        "books = pd.read_csv(file_path)\n",
        "books.head()"
      ],
      "metadata": {
        "id": "TkvIYtnPc1nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Data\n",
        "file_path = ('/content/drive/MyDrive/Book_recommendation_system/Ratings.csv')\n",
        "ratings = pd.read_csv(file_path)\n",
        "ratings.head()"
      ],
      "metadata": {
        "id": "TfvnRrrfc9eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dimension of dataset\n",
        "print('This shape of Books datasheet is : ',books.shape)\n",
        "print('='*50)\n",
        "print('This shape of Ratings datasheet is : ',ratings.shape)\n",
        "print('='*50)\n",
        "print('This shape of Users datasheet is : ',users.shape)"
      ],
      "metadata": {
        "id": "UvDYSJqCdFAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values(df):\n",
        "    mis_val=df.isnull().sum()\n",
        "    mis_val_percent=round(df.isnull().mean().mul(100),2)\n",
        "    mz_table=pd.concat([mis_val,mis_val_percent],axis=1)\n",
        "    mz_table=mz_table.rename(\n",
        "    columns={df.index.name:'col_name',0:'Missing Values',1:'% of Total Values'})\n",
        "    mz_table['Data_type']=df.dtypes\n",
        "    mz_table=mz_table.sort_values('% of Total Values',ascending=False)\n",
        "    return mz_table.reset_index()"
      ],
      "metadata": {
        "id": "9Wo-SL1BdVkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(users)"
      ],
      "metadata": {
        "id": "zSWr5kVfdbVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age have around 39% missing Value"
      ],
      "metadata": {
        "id": "tDK1TIK5dzP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Age distribution\n"
      ],
      "metadata": {
        "id": "zJJ78-NAeFm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.Age.hist(bins=[0, 10, 20, 30, 40, 50,75, 100,])\n",
        "plt.title('Age Distribution\\n')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5kHcntTcdg1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Most of Active users are among those in their 20-30s."
      ],
      "metadata": {
        "id": "8-NLboCFfGa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now let's check for outliers in age columns"
      ],
      "metadata": {
        "id": "4PuKWHIGfVIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(y='Age', data=users)\n",
        "plt.title('Find outlier data in Age column')"
      ],
      "metadata": {
        "id": "LKL3ILi4e466"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(users.Age.unique()))"
      ],
      "metadata": {
        "id": "eXCYnaJBfkSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age: 244\n",
        "So We have outlier data  in Age."
      ],
      "metadata": {
        "id": "QxEWFIh2fz2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let Find our unique value in Location columns"
      ],
      "metadata": {
        "id": "0eajLwC7gF9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.Location.unique()"
      ],
      "metadata": {
        "id": "cp0-Pg1Yfob_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.Location.nunique()"
      ],
      "metadata": {
        "id": "e2f7uyP0gWaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "57339 Unique Value it's"
      ],
      "metadata": {
        "id": "rnwHRs_Jgryh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So let's Create Column Country"
      ],
      "metadata": {
        "id": "gTF3yb1Pqsel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in users:\n",
        "    users['Country']=users.Location.str.extract(r'\\,+\\s?(\\w*\\s?\\w*)\\\"*$')"
      ],
      "metadata": {
        "id": "lRUR0OCPgZwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.Country.nunique()"
      ],
      "metadata": {
        "id": "MUgR8PayrFFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop location column\n",
        "users.drop('Location',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "h_kXGOU4rKy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head(2)"
      ],
      "metadata": {
        "id": "QIIYcqMArNpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isnull().sum()"
      ],
      "metadata": {
        "id": "mwiA6UEMrQvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users['Country']=users['Country'].astype('str')"
      ],
      "metadata": {
        "id": "XOdOuTy1rVcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=list(users.Country.unique())\n",
        "a=set(a)\n",
        "a=list(a)\n",
        "a = [x for x in a if x is not None]\n",
        "a.sort()\n",
        "print(a)"
      ],
      "metadata": {
        "id": "db_KbVyPrYNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few Data has Misspelling Let's Correct it."
      ],
      "metadata": {
        "id": "HKn086RhsQH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users['Country'].replace(['','01776','02458','19104','23232','30064','85021','87510','alachua','america','austria','autralia','cananda','geermany','italia','united kindgonm','united sates','united staes','united state','united states','us'],\n",
        "                           ['other','usa','usa','usa','usa','usa','usa','usa','usa','usa','australia','australia','canada','germany','italy','united kingdom','usa','usa','usa','usa','usa'],inplace=True)"
      ],
      "metadata": {
        "id": "A85bTeGCsBRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7KwoPugRsPXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(y='Country',data=users,order=pd.value_counts(users['Country']).iloc[:10].index)\n",
        "plt.title('Count of users Country wise')"
      ],
      "metadata": {
        "id": "q-H82G0LsC7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the users are from USA"
      ],
      "metadata": {
        "id": "ANP2J_SusYgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's treat Outliears in user age."
      ],
      "metadata": {
        "id": "gY95zx0XseUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(users.Age)\n",
        "plt.title('Age Distribution Plot')"
      ],
      "metadata": {
        "id": "vON4QFLhsou5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age Values below 5 and above 100 do not make much sense for our  book rating case hence replacing these by Nans"
      ],
      "metadata": {
        "id": "hDRyXU62s7MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# outlier data became NaN\n",
        "users.loc[(users.Age > 100) | (users.Age < 5), 'Age'] = np.nan"
      ],
      "metadata": {
        "id": "N3L7ikdkssod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "Cu5LzHjutU7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age has Positive skewness( Right tail) so we can use median to fill Nan Values ,but for this we don't like to fill Nan Value just for one range of age. To handle this will use Country Columns to Fill Nan"
      ],
      "metadata": {
        "id": "lhj7PYYDtw1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users['Age'] = users['Age'].fillna(users.groupby('Country')['Age'].transform('median'))"
      ],
      "metadata": {
        "id": "AZSejUJstX2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "W9D24GSbubCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still We have 276 Nan Values let's fill these with mean"
      ],
      "metadata": {
        "id": "HFn-qjFlunMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users['Age'].fillna(users.Age.mean(),inplace=True)"
      ],
      "metadata": {
        "id": "iUBrBmsPueL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "0na8iY1puzNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now Books_Dataset"
      ],
      "metadata": {
        "id": "0MZ45Db4u6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books.head(2)"
      ],
      "metadata": {
        "id": "6NUJrQb5u2SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 Authors which have written the most books"
      ],
      "metadata": {
        "id": "28YsPBeTvSo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(y='Book-Author',data=books,order=pd.value_counts(books['Book-Author']).iloc[:10].index)\n",
        "plt.title('Top 10 Authors')"
      ],
      "metadata": {
        "id": "LNMcP7XPvKR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 Publisher which have Published the most books"
      ],
      "metadata": {
        "id": "6f1jcd_DvlTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(y='Publisher',data=books,order=pd.value_counts(books['Publisher']).iloc[:10].index)\n",
        "plt.title('Top 10 Publishers')"
      ],
      "metadata": {
        "id": "LtpAVvwivcse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books['Year-Of-Publication']=books['Year-Of-Publication'].astype('str')\n",
        "a=list(books['Year-Of-Publication'].unique())\n",
        "a=set(a)\n",
        "a=list(a)\n",
        "a = [x for x in a if x is not None]\n",
        "a.sort()\n",
        "print(a)"
      ],
      "metadata": {
        "id": "JKU4r5TIv0Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#investigating the rows having 'DK Publishing Inc' as yearOfPublication\n",
        "books.loc[books['Year-Of-Publication'] == 'DK Publishing Inc',:]"
      ],
      "metadata": {
        "id": "PBJeKj5zwAst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it can be seen from above that there are some incorrect entries in year of publication field . it looks like publisher names \" DK Publishing\" and \"Gallimard\" have been in correctly loaded as year of publisher in dataset due to some errors in csv files"
      ],
      "metadata": {
        "id": "TNr8ilPqwwHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From above, it is seen that bookAuthor is incorrectly loaded with bookTitle, hence making required corrections\n",
        "#ISBN '0789466953'\n",
        "books.loc[books.ISBN == '0789466953','Year-Of-Publication'] = 2000\n",
        "books.loc[books.ISBN == '0789466953','Book-Author'] = \"James Buckley\"\n",
        "books.loc[books.ISBN == '0789466953','Publisher'] = \"DK Publishing Inc\"\n",
        "books.loc[books.ISBN == '0789466953','Book-Title'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)\"\n",
        "\n",
        "#ISBN '078946697X'\n",
        "books.loc[books.ISBN == '078946697X','Year-Of-Publication'] = 2000\n",
        "books.loc[books.ISBN == '078946697X','Book-Author'] = \"Michael Teitelbaum\"\n",
        "books.loc[books.ISBN == '078946697X','Publisher'] = \"DK Publishing Inc\"\n",
        "books.loc[books.ISBN == '078946697X','Book-Title'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\"\n",
        "\n",
        "#rechecking\n",
        "books.loc[(books.ISBN == '0789466953') | (books.ISBN == '078946697X'),:]\n",
        "#corrections done"
      ],
      "metadata": {
        "id": "ci4xgz5iwKZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#investigating the rows having 'Gallimard' as yearOfPublication\n",
        "books.loc[books['Year-Of-Publication'] == 'Gallimard',:]"
      ],
      "metadata": {
        "id": "cD9damj-xlxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making required corrections as above, keeping other fields intact\n",
        "books.loc[books.ISBN == '2070426769','Year-Of-Publication'] = 2003\n",
        "books.loc[books.ISBN == '2070426769','Book-Author'] = \"Jean-Marie Gustave Le ClÃ?Â©zio\"\n",
        "books.loc[books.ISBN == '2070426769','Publisher'] = \"Gallimard\"\n",
        "books.loc[books.ISBN == '2070426769','Book-Title'] = \"Peuple du ciel, suivi de 'Les Bergers\"\n",
        "\n",
        "\n",
        "books.loc[books.ISBN == '2070426769',:]"
      ],
      "metadata": {
        "id": "Z5UgGhp6xpyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books['Year-Of-Publication']=pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
        "\n",
        "print(sorted(books['Year-Of-Publication'].unique()))\n",
        "#Now it can be seen that yearOfPublication has all values as integers"
      ],
      "metadata": {
        "id": "FQvnGbZ-yAao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value 0 for year of publication is invalid and as this dataset  was published in 2004: We have assumed that the years after 2006 to be invalid and setting invalid years is Nan"
      ],
      "metadata": {
        "id": "tTVtqdSVyaNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference of the fact: http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
        "\n"
      ],
      "metadata": {
        "id": "q_O_Z9oFy7YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books.loc[(books['Year-Of-Publication'] > 2006) | (books['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
        "\n",
        "#replacing NaNs with median value of Year-Of-Publication\n",
        "books['Year-Of-Publication'].fillna(round(books['Year-Of-Publication'].median()), inplace=True)"
      ],
      "metadata": {
        "id": "m2CJmw5eyCiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping last three columns containing image URLs which will not be required for analysis\n",
        "books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "ZoT88RTuy_jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.isna().sum()"
      ],
      "metadata": {
        "id": "7Voqc4xdzDps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring 'publisher' column\n",
        "books.loc[books.Publisher.isnull(),:]\n",
        "#two NaNs"
      ],
      "metadata": {
        "id": "DwRx2UxNzGk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling Nan of Publisher with others\n",
        "books.Publisher.fillna('other',inplace=True)"
      ],
      "metadata": {
        "id": "EWRNgQvJzQAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring 'Book-Author' column\n",
        "books.loc[books['Book-Author'].isnull(),:]"
      ],
      "metadata": {
        "id": "YI2UNXCQzTGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling Nan of Book-Author with others\n",
        "books['Book-Author'].fillna('other',inplace=True)"
      ],
      "metadata": {
        "id": "8NVf0gYAzWAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.isna().sum()"
      ],
      "metadata": {
        "id": "V0PvRmEvzYlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratings_Dataset"
      ],
      "metadata": {
        "id": "_NhVrHMmK-mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(2)"
      ],
      "metadata": {
        "id": "vH7KWRVRLBDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings dataset should have books only which exist in our books dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hWq_GFrxLbCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_new = ratings[ratings.ISBN.isin(books.ISBN)]\n",
        "ratings.shape,ratings_new.shape"
      ],
      "metadata": {
        "id": "dV6N5o2-LW-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that many rows having book ISBN not part of books dataset got dropped off"
      ],
      "metadata": {
        "id": "sZ6ZpyMiLkxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings dataset should have ratings from users which exist in users dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "FMPR0313Lnzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of dataset before dropping\",ratings_new.shape)\n",
        "ratings_new = ratings_new[ratings_new['User-ID'].isin(users['User-ID'])]\n",
        "print(\"shape of dataset after dropping\",ratings_new.shape)"
      ],
      "metadata": {
        "id": "DvQlag5mLgZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that no new user was there in ratings dataset."
      ],
      "metadata": {
        "id": "5GrEjGxiLuNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the ratings are distributed\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KJlG2HI8Lvcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc(\"font\", size=15)\n",
        "ratings_new['Book-Rating'].value_counts(sort=False).plot(kind='bar')\n",
        "plt.title('Rating Distribution\\n')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HEx7CSznLrye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ratings are very unevenly distributed, and the vast majority of ratings are 0 .As quoted in the description of the dataset - BX-Book-Ratings contains the book rating information. Ratings are either explicit, expressed on a scale from 1-10 higher values denoting higher appreciation, or implicit, expressed by 0.Hence segragating implicit and explict ratings datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "3I3K_umhL5r0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hence segragating implicit and explict ratings datasets\n",
        "ratings_explicit = ratings_new[ratings_new['Book-Rating'] != 0]\n",
        "ratings_implicit = ratings_new[ratings_new['Book-Rating'] == 0]"
      ],
      "metadata": {
        "id": "lnc6l1CwL7dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ratings_explicit dataset shape',ratings_explicit.shape)\n",
        "print('ratings_implicit dataset',ratings_implicit.shape)"
      ],
      "metadata": {
        "id": "b1emARoZL_Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(data=ratings_explicit , x='Book-Rating', palette='rocket_r')"
      ],
      "metadata": {
        "id": "PL3L-cTXMDkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observe that higher ratings are more common amongst users and rating 8 has been rated highest number of times"
      ],
      "metadata": {
        "id": "emCl9vaoNmFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's find the top 5 books which are rated by most number of users."
      ],
      "metadata": {
        "id": "LIXfJOOxNm9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_count = pd.DataFrame(ratings_explicit.groupby('ISBN')['Book-Rating'].count())\n",
        "rating_count.sort_values('Book-Rating', ascending=False).head()"
      ],
      "metadata": {
        "id": "49eTS1xvNiSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The book with ISBN '0316666343' received the most rating counts. Let’s find out what book it is, and what books are in the top 5."
      ],
      "metadata": {
        "id": "EUxkz_D3Nzxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "most_rated_books = pd.DataFrame(['0316666343', '0971880107', '0385504209', '0312195516', '0060928336'], index=np.arange(5), columns = ['ISBN'])\n",
        "most_rated_books_summary = pd.merge(most_rated_books, books, on='ISBN')\n",
        "most_rated_books_summary"
      ],
      "metadata": {
        "id": "Ufn5uFRPNtwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The book that received the most rating counts in this data set is Rich Shapero’s “Wild Animus”. And there is something in common among these five books that received the most rating counts — they are all novels. So it is conclusive that novels are popular and likely receive more ratings.\n",
        "\n"
      ],
      "metadata": {
        "id": "dB74ybQ-N8ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column Rating average\n",
        "ratings_explicit['Avg_Rating']=ratings_explicit.groupby('ISBN')['Book-Rating'].transform('mean')\n",
        "# Create column Rating sum\n",
        "ratings_explicit['Total_No_Of_Users_Rated']=ratings_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
      ],
      "metadata": {
        "id": "GpIDmWShN4wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.head()"
      ],
      "metadata": {
        "id": "J913ccUJOBNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging All Dataset."
      ],
      "metadata": {
        "id": "bK5xp7PJOGmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Dataset=users.copy()\n",
        "Final_Dataset=pd.merge(Final_Dataset,ratings_explicit,on='User-ID')\n",
        "Final_Dataset=pd.merge(Final_Dataset,books,on='ISBN')"
      ],
      "metadata": {
        "id": "B7YZEnpwOElX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Dataset.head()"
      ],
      "metadata": {
        "id": "Gp2oa0-hOLDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(Final_Dataset)"
      ],
      "metadata": {
        "id": "rEEPLIDuORRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Dataset.shape"
      ],
      "metadata": {
        "id": "DFfJk1vTOV5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Popularity Based Filtering"
      ],
      "metadata": {
        "id": "t853P4NO5UDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the name suggests Popularity based recommendation system works with the trend. It basically uses the items which are in trend right now. For example, if any book which is usually bought by every new user then there are chances that it may suggest that book to the user who just signed up.\n",
        "\n",
        "Book weighted avg formula:\n",
        "\n",
        "Weighted Rating(WR)=[vR/(v+m)]+[mC/(v+m)]\n",
        "\n",
        "where,\n",
        "\n",
        "v is the number of votes for the books;\n",
        "\n",
        "m is the minimum votes required to be listed in the chart;\n",
        "\n",
        "R is the average rating of the book; and\n",
        "\n",
        "C is the mean vote across the whole report.\n",
        "\n",
        "Now we find the values of v,m,R,C."
      ],
      "metadata": {
        "id": "uxRoO4rw5YPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C= Final_Dataset['Avg_Rating'].mean()\n",
        "m= Final_Dataset['Total_No_Of_Users_Rated'].quantile(0.90)\n",
        "Top_Books = Final_Dataset.loc[Final_Dataset['Total_No_Of_Users_Rated'] >= m]\n",
        "print(f'C={C} , m={m}')\n",
        "Top_Books.shape"
      ],
      "metadata": {
        "id": "8yQvPXMqOWgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used 90th percentile as our cutoff. In other words, for a book to feature in the charts, it must have more votes than at least 90% of the books in the list.\n",
        "We see that there are 38570 books which qualify to be in this list. Now, we need to calculate our metric for each qualified book. To do this, we will define a function, weighted_rating() and define a new feature score, of which we’ll calculate the value by applying this function to our DataFrame of qualified books:"
      ],
      "metadata": {
        "id": "euQV68It5pBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_rating(x, m=m, C=C):\n",
        "    v = x['Total_No_Of_Users_Rated']\n",
        "    R = x['Avg_Rating']\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
        "\n",
        "\n",
        "Top_Books['Score'] = Top_Books.apply(weighted_rating,axis=1)\n",
        "\n",
        "\n",
        "#Sorting books based on score calculated above\n",
        "Top_Books = Top_Books.sort_values('Score', ascending=False)"
      ],
      "metadata": {
        "id": "sN4vKwJT5oqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keeping only one entry of each book\n",
        "Top_Books=Top_Books.sort_values('Score', ascending=False).drop_duplicates('ISBN').sort_index()\n",
        "cm=sns.light_palette('yellow',as_cmap=True)\n",
        "#Sorting books based on score calculated above\n",
        "Top_Books = Top_Books.sort_values('Score', ascending=False)\n",
        "\n",
        "#Printing the top 20 books\n",
        "Top_Books[['Book-Title', 'Total_No_Of_Users_Rated', 'Avg_Rating', 'Score']].reset_index(drop=True).head(20).style.background_gradient(cmap=cm)"
      ],
      "metadata": {
        "id": "hqF1ZYNo5wOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Popularity based recommender provide a general chart of recommended books to all the users. They are not sensitive to the interests and tastes of a particular user."
      ],
      "metadata": {
        "id": "0MM2cB2L55vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Based Collaborative Filtering Recommender"
      ],
      "metadata": {
        "id": "TKcDiV8M6AzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of the recommender system is to predict user preference for a set of items based on the past experience. Two the most popular approaches are Content-Based and Collaborative Filtering.\n",
        "Collaborative filtering is a technique used by websites like Amazon, YouTube, and Netflix. It filters out items that a user might like on the basis of reactions of similar users. There are two categories of collaborative filtering algorithms: memory based and model based.\n",
        "Model based approach involves building machine learning algorithms to predict user's ratings. They involve dimensionality reduction methods that reduce high dimensional matrix containing abundant number of missing values with a much smaller matrix in lower-dimensional space.\n",
        "The goal of this section is to compare SVD and NMF algorithms, try different configurations of parameters and explore obtained results."
      ],
      "metadata": {
        "id": "T-9IDQ-K9AlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import math\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uB2vIcq79EHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis will focus on book recommendations based on Book-Crossing dataset. To reduce the dimensionality of the dataset and avoid running into memory error we will focus on users with at least 3 ratings and top 10% most frequently rated books.\n",
        "The recommender systems will be built using surprise package (Matrix Factorization - based models).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bk_5bHHi9Gzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.rename(columns = {'User-ID':'user_id' ,'ISBN':'isbn' ,'Book-Rating':'book_rating'},inplace=True)"
      ],
      "metadata": {
        "id": "dtGQrPrc9KEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ratings_threshold = 3\n",
        "\n",
        "filter_users = ratings_explicit['user_id'].value_counts()\n",
        "filter_users_list = filter_users[filter_users >= user_ratings_threshold].index.to_list()\n",
        "\n",
        "df_ratings_top = ratings_explicit[ratings_explicit['user_id'].isin(filter_users_list)]\n",
        "\n",
        "print('Filter: users with at least %d ratings\\nNumber of records: %d' % (user_ratings_threshold, len(df_ratings_top)))"
      ],
      "metadata": {
        "id": "k6GM4uOg9N4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratings_threshold_perc = 0.1\n",
        "book_ratings_threshold = len(df_ratings_top['isbn'].unique()) * book_ratings_threshold_perc\n",
        "\n",
        "filter_books_list = df_ratings_top['isbn'].value_counts().head(int(book_ratings_threshold)).index.to_list()\n",
        "df_ratings_top = df_ratings_top[df_ratings_top['isbn'].isin(filter_books_list)]\n",
        "\n",
        "print('Filter: top %d%% most frequently rated books\\nNumber of records: %d' % (book_ratings_threshold_perc*100, len(df_ratings_top)))"
      ],
      "metadata": {
        "id": "XjnLzZdh9R9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVD and NMF models comparison\n",
        "Singular Value Decomposition (SVD) and Non-negative Matrix Factorization (NMF) are matrix factorization techniques used for dimensionality reduction. Surprise package provides implementation of those algorithms."
      ],
      "metadata": {
        "id": "qNgtz1989WIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install surprise"
      ],
      "metadata": {
        "id": "39C6pGgg9bNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader\n",
        "from surprise import SVD, NMF\n",
        "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "jVG_6a-v-Py1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_ratings_top.copy()\n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "data = Dataset.load_from_df(df[['user_id', 'isbn', 'book_rating']], reader)"
      ],
      "metadata": {
        "id": "CQrfWU7o9i9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svd = SVD()\n",
        "cv_results_svd = cross_validate(model_svd, data, cv=3)\n",
        "pd.DataFrame(cv_results_svd).mean()"
      ],
      "metadata": {
        "id": "053kcIOv-T0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nmf = NMF()\n",
        "cv_results_nmf = cross_validate(model_nmf, data, cv=3)\n",
        "pd.DataFrame(cv_results_nmf).mean()"
      ],
      "metadata": {
        "id": "KoPN1-uI-fYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's clear that for the given dataset much better results can be obtained with SVD approach - both in terms of accuracy and training / testing time."
      ],
      "metadata": {
        "id": "HMKjw5qC-ke6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimisation of SVD algorithm"
      ],
      "metadata": {
        "id": "acnKLab-_Xtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search Cross Validation computes accuracy metrics for an algorithm on various combinations of parameters, over a cross-validation procedure. It's useful for finding the best configuration of parameters.\n",
        "\n",
        "It is used to find the best setting of parameters:\n",
        "\n",
        "n_factors - the number of factors\n",
        "\n",
        "n_epochs - the number of iteration of the SGD procedure\n",
        "\n",
        "lr_all - the learning rate for all parameters\n",
        "\n",
        "reg_all - the regularization term for all parameters\n",
        "\n",
        "As a result, regarding the majority of parameters, the default setting is the\n",
        "\n",
        "most optimal one. The improvement obtained with Grid Search is very small."
      ],
      "metadata": {
        "id": "0sxll4Wg_cB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_factors': [80,100],\n",
        "              'n_epochs': [5, 20],\n",
        "              'lr_all': [0.002, 0.005],\n",
        "              'reg_all': [0.2, 0.4]}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "print(gs.best_score['rmse'])\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "jkQrbm96-h0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Collaborative Filtering model results"
      ],
      "metadata": {
        "id": "fiiJIbs3_qOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, let's examine in detail the results obtained by the SVD model that provided the best RMSE score."
      ],
      "metadata": {
        "id": "kaa22vGI_wZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "model = SVD(n_factors=80, n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
        "model.fit(trainset)\n",
        "predictions = model.test(testset)"
      ],
      "metadata": {
        "id": "tal0-XIk_mRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.DataFrame(predictions, columns=['user_id', 'isbn', 'actual_rating', 'pred_rating', 'details'])\n",
        "df_pred['impossible'] = df_pred['details'].apply(lambda x: x['was_impossible'])\n",
        "df_pred['pred_rating_round'] = df_pred['pred_rating'].round()\n",
        "df_pred['abs_err'] = abs(df_pred['pred_rating'] - df_pred['actual_rating'])\n",
        "df_pred.drop(['details'], axis=1, inplace=True)\n",
        "df_pred.sample(5)"
      ],
      "metadata": {
        "id": "4I573adu_0Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of actual and predicted ratings in the test set According to the distribution of actual ratings of books in the test set, the biggest part of users give positive scores - between 7 and 10. The mode equals 8 but count of ratings 7, 9, 10 is also noticeable. The distribution of predicted ratings in the test set is visibly different. One more time, 8 is a mode but scores 7, 9 and 10 are clearly less frequent.\n",
        "It shows that the recommender system is not perfect and it cannot reflect the real distribution of book ratings."
      ],
      "metadata": {
        "id": "UkhS0w2CAu4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palette = sns.color_palette(\"RdBu\", 10)\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 4))\n",
        "\n",
        "sns.countplot(x='actual_rating', data=df_pred, palette=palette, ax=ax1)\n",
        "ax1.set_title('Distribution of actual ratings of books in the test set')\n",
        "\n",
        "sns.countplot(x='pred_rating_round', data=df_pred, palette=palette, ax=ax2)\n",
        "ax2.set_title('Distribution of predicted ratings of books in the test set')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "exwvmBcIAv59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Absolute error of predicted ratings\n",
        "The distribution of absolute errors is right-skewed, showing that the majority of errors is small: between 0 and 1. There is a long tail that indicates that there are several observations for which the absolute error was close to 10.\n",
        "How good/bad the model is with predicting certain scores? As expected from the above charts, the model deals very well with predicting score = 8 (the most frequent value). The further the rating from score = 8, the higher the absolute error. The biggest errors happen to observations with scores 1 or 2 which indicates that probably the model is predicting high ratings for those observations."
      ],
      "metadata": {
        "id": "uNhg-4UUA5Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred_err = df_pred.groupby('actual_rating')['abs_err'].mean().reset_index()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 4))\n",
        "\n",
        "sns.distplot(df_pred['abs_err'], color='#2f6194', ax=ax1)\n",
        "ax1.set_title('Distribution of absolute error in test set')\n",
        "\n",
        "sns.barplot(x='actual_rating', y='abs_err', data=df_pred_err, palette=palette, ax=ax2)\n",
        "ax2.set_title('Mean absolute error for rating in test set')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WN-VSrSEA0HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of predicted ratings of a particular user\n",
        "For this part of the analysis, the user with id 193458 was selected. By analyzing book ratings by this user, it can be noted that he/she likes diverse types of readings: English romantic novels (Pride and Prejudice, Sense and Sensibility), fantasy (Narnia) as well as historical novels (Schindler's List). Among the recommended books there are other works from Narnia's series, two historical novels and one romance which correlates with user's previous preferences."
      ],
      "metadata": {
        "id": "Z08v83IoBALj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_books = books.copy()\n",
        "df_books.rename(columns = {'ISBN':'isbn' ,'Book-Title':'book_title'},inplace=True)\n",
        "df_ext = df.merge(df_books[['isbn', 'book_title']], on='isbn', how='left')\n",
        "df_ext = df_ext.merge(df_pred[['isbn', 'user_id', 'pred_rating']], on=['isbn', 'user_id'], how='left')"
      ],
      "metadata": {
        "id": "5QCUUMutA9WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train set: Top rated books"
      ],
      "metadata": {
        "id": "mnCT9p9vBMAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_user_id = 193458\n",
        "df_user = df_ext[df_ext['user_id']==selected_user_id]\n",
        "\n",
        "df_user[(df_user['pred_rating'].isna())&(df_user['book_rating']>=9)].sample(10)"
      ],
      "metadata": {
        "id": "RilhW-CSBKJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test set: predicted top rated books"
      ],
      "metadata": {
        "id": "QGgqTRx2B-KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_user[df_user['pred_rating'].notna()].sort_values('pred_rating', ascending=False).head(5)"
      ],
      "metadata": {
        "id": "FHR71VBvB4p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test set: actual top rated books\n"
      ],
      "metadata": {
        "id": "iDuikmnACJik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_user[df_user['pred_rating'].notna()].sort_values('book_rating', ascending=False).head(5)"
      ],
      "metadata": {
        "id": "uAYH-ns6CEcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering based Recommendation System--(Item-Item Based)"
      ],
      "metadata": {
        "id": "jT5BEcF6DKE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.spatial.distance import correlation\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from contextlib import contextmanager\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import re\n",
        "from scipy.sparse import csr_matrix"
      ],
      "metadata": {
        "id": "sXGkQaHpCyPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_top.head()"
      ],
      "metadata": {
        "id": "vh4FUpzHDQzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_top.rename(columns={'user_id':'userID' ,'isbn':'ISBN','book_rating':'bookRating'},inplace=True)"
      ],
      "metadata": {
        "id": "ya25gUIUDTwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_top.head()"
      ],
      "metadata": {
        "id": "-gYh7zf4Dbbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing KNN\n"
      ],
      "metadata": {
        "id": "QHMP0_CtLwYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating ratings matrix from explicit ratings table\n",
        "ratings_matrix = df_ratings_top.pivot(index='userID', columns='ISBN', values='bookRating')\n",
        "userID = ratings_matrix.index\n",
        "ISBN = ratings_matrix.columns\n",
        "print(ratings_matrix.shape)\n",
        "ratings_matrix.head()\n",
        "#Notice that most of the values are NaN (undefined) implying absence of ratings"
      ],
      "metadata": {
        "id": "CnBTkIqmL_TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_users = ratings_matrix.shape[0] #considering only those users who gave explicit ratings\n",
        "n_books = ratings_matrix.shape[1]\n",
        "print (n_users, n_books)"
      ],
      "metadata": {
        "id": "mo0IenJRMBbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_matrix.fillna(0, inplace = True)\n",
        "ratings_matrix = ratings_matrix.astype(np.int32)"
      ],
      "metadata": {
        "id": "iwQAkzxfMGrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking first few rows\n",
        "ratings_matrix.head(5)"
      ],
      "metadata": {
        "id": "Po0IbMkiMM7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity = 1.0-len(ratings_explicit)/float(ratings_explicit.shape[0]*n_books)\n",
        "print ('The sparsity level of Book Crossing dataset is ' +  str(sparsity*100) + ' %')"
      ],
      "metadata": {
        "id": "RFBhAsqMMRID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_book_rating = pd.merge(ratings, books, on = 'ISBN')\n",
        "columns = ['Book-Author','Year-Of-Publication', 'Publisher']"
      ],
      "metadata": {
        "id": "tP1rwWKYMXaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_book_rating = combine_book_rating.drop(columns, axis = 1)\n",
        "combine_book_rating.rename(columns={'User-ID':'userID','Book-Title':'bookTitle','Book-Rating':'bookRating'},inplace=True)\n",
        "combine_book_rating.head()"
      ],
      "metadata": {
        "id": "KlSLz4MwMcka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_book_rating = combine_book_rating.dropna(axis = 0, subset = ['bookTitle'])"
      ],
      "metadata": {
        "id": "9g5h3OiQMe4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratingcount = (combine_book_rating.\n",
        "                    groupby(by = ['bookTitle',])['bookRating'].\n",
        "                    count().\n",
        "                    reset_index().\n",
        "                    rename(columns = {'bookRating':'TotalRatingCount'})\n",
        "                    [['bookTitle','TotalRatingCount']])"
      ],
      "metadata": {
        "id": "0kjhwjwNMizV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratingcount.head()"
      ],
      "metadata": {
        "id": "xV1odQIWMlsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the rating data with the total rating count data, this gives us exactly what we need to filter out the lesser known books"
      ],
      "metadata": {
        "id": "0Ce3tpGxMsmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_with_totalratingcount = combine_book_rating.merge(book_ratingcount, left_on = 'bookTitle', right_on = 'bookTitle', how = 'inner' )"
      ],
      "metadata": {
        "id": "NMsdOQiJMo4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_with_totalratingcount.head()"
      ],
      "metadata": {
        "id": "DjAm6pUnMwz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "print(book_ratingcount['TotalRatingCount'].describe())"
      ],
      "metadata": {
        "id": "wmX-CqmTNOyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The median book has been rated only once. Let’s look at the top of the distribution:"
      ],
      "metadata": {
        "id": "WCq3APaQNU72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(book_ratingcount['TotalRatingCount'].quantile(np.arange(.9,1,.01)))"
      ],
      "metadata": {
        "id": "MTU2fiE6NStx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About 1% of the books received 50 or more ratings. Because we have so many books in our data, we will limit it to the top 1%.\n",
        "\n"
      ],
      "metadata": {
        "id": "-2g09EAJNbgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popularity_threshold = 50\n",
        "rating_popular_book = rating_with_totalratingcount.query('TotalRatingCount >= @popularity_threshold')"
      ],
      "metadata": {
        "id": "LxF-UrSoNYUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_popular_book.head()"
      ],
      "metadata": {
        "id": "AL6tnQ2QNf81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not rating_popular_book[rating_popular_book.duplicated(['userID', 'bookTitle'])].empty:\n",
        "    initial_rows = rating_popular_book.shape[0]\n",
        "\n",
        "    print('Initial dataframe shape {0}'.format(rating_popular_book.shape))\n",
        "    rating_popular_book = rating_popular_book.drop_duplicates(['userID', 'bookTitle'])\n",
        "    current_rows = rating_popular_book.shape[0]\n",
        "    print('New dataframe shape {0}'.format(rating_popular_book.shape))\n",
        "    print('Removed {0} rows'.format(initial_rows - current_rows))"
      ],
      "metadata": {
        "id": "HUgPuvMrNi58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot = rating_popular_book.pivot(index = 'bookTitle',columns = 'userID', values = 'bookRating').fillna(0)\n",
        "us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)"
      ],
      "metadata": {
        "id": "C6cr_lPpNtbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the Nearest Neighbors\n",
        "\n"
      ],
      "metadata": {
        "id": "UpGcob4yNxrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "model_knn.fit(us_canada_user_rating_matrix)"
      ],
      "metadata": {
        "id": "znxlCWteNwCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test our model and Make few Recommnedations\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5lq74-vN53x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_index = np.random.choice(us_canada_user_rating_pivot.shape[0])\n",
        "distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index, :].values.reshape((1, -1)), n_neighbors = 6)\n",
        "\n",
        "for i in range(0, len(distances.flatten())):\n",
        "    if i == 0:\n",
        "        print('Recommendations for {0}:\\n'.format(us_canada_user_rating_pivot.index[query_index]))\n",
        "    else:\n",
        "        print('{0}: {1}, with distance of {2}:'.format(i, us_canada_user_rating_pivot.index[indices.flatten()[i]], distances.flatten()[i]))"
      ],
      "metadata": {
        "id": "Jb7j3BWxN1He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot2 = rating_popular_book.pivot(index = 'userID', columns = 'bookTitle', values = 'bookRating').fillna(0)"
      ],
      "metadata": {
        "id": "SPQgwfDnN9f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot2.head()"
      ],
      "metadata": {
        "id": "gRg4ZjEuN_xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot2.shape"
      ],
      "metadata": {
        "id": "4JbJqITjOB0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = us_canada_user_rating_pivot2.values.T\n",
        "X.shape"
      ],
      "metadata": {
        "id": "QLHMcbe5OFsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "SVD = TruncatedSVD(n_components=12, random_state=17)\n",
        "matrix = SVD.fit_transform(X)\n",
        "matrix.shape"
      ],
      "metadata": {
        "id": "p1p1kcNcOIMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = np.corrcoef(matrix)\n",
        "corr.shape"
      ],
      "metadata": {
        "id": "eDbrKpywO77y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find books similar to Harry Potter and the Sorcerer's Stone (Book 1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N27XE8uQPAZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_book_title = us_canada_user_rating_pivot2.columns\n",
        "us_canada_book_list = list(us_canada_book_title)\n",
        "coffey_hands = us_canada_book_list.index(\"Harry Potter and the Sorcerer's Stone (Book 1)\")"
      ],
      "metadata": {
        "id": "eiu7M5VgO-aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_coffey_hands  = corr[coffey_hands]"
      ],
      "metadata": {
        "id": "UFk010DGPD7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(us_canada_book_title[(corr_coffey_hands<1.0) & (corr_coffey_hands>0.9)])"
      ],
      "metadata": {
        "id": "wxu82L-rPGuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thats Great!!"
      ],
      "metadata": {
        "id": "ZZEm4bPUPNZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering based Recommendation System--(User-Item based)"
      ],
      "metadata": {
        "id": "ZVkzEaMpPR9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.head()\n",
        "ratings_explicit.rename(columns={'user_id':'User-ID','isbn':'ISBN','book_rating':'Book-Rating'},inplace=True)"
      ],
      "metadata": {
        "id": "jNJ8Qch1POAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.head()"
      ],
      "metadata": {
        "id": "gktFFW1oPV30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_interactions_count_df = ratings_explicit.groupby(['ISBN', 'User-ID']).size().groupby('User-ID').size()\n",
        "print('# of users: %d' % len(users_interactions_count_df))\n",
        "\n",
        "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 100].reset_index()[['User-ID']]\n",
        "print('# of users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
      ],
      "metadata": {
        "id": "9rEeGclrPYHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('# of interactions: %d' % len(ratings_explicit))\n",
        "interactions_from_selected_users_df = ratings_explicit.merge(users_with_enough_interactions_df,\n",
        "               how = 'right',\n",
        "               left_on = 'User-ID',\n",
        "               right_on = 'User-ID')\n",
        "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
      ],
      "metadata": {
        "id": "YZyey3--PbwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_from_selected_users_df.head(10)"
      ],
      "metadata": {
        "id": "U8OHGrrQPhgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "6jSW6LGxPpKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "\n",
        "interactions_full_df = interactions_from_selected_users_df.groupby(['ISBN', 'User-ID'])['Book-Rating'].sum().apply(smooth_user_preference).reset_index()\n",
        "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
        "interactions_full_df.head()"
      ],
      "metadata": {
        "id": "bxH_T2YnPtpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hXB_1Ar2PyAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
        "                                   stratify=interactions_full_df['User-ID'],\n",
        "                                   test_size=0.20,\n",
        "                                   random_state=42)\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))"
      ],
      "metadata": {
        "id": "i9DNFGxwP1IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_test_df.head()"
      ],
      "metadata": {
        "id": "Dx15bDCiP41P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sparse pivot table with users in rows and items in columns\n",
        "users_items_pivot_matrix_df = interactions_train_df.pivot(index='User-ID',\n",
        "                                                          columns='ISBN',\n",
        "                                                          values='Book-Rating').fillna(0)\n",
        "\n",
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "I08CGFyDQBzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix = users_items_pivot_matrix_df.values\n",
        "users_items_pivot_matrix[:10]"
      ],
      "metadata": {
        "id": "iAoyI29rQCuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_ids = list(users_items_pivot_matrix_df.index)\n",
        "users_ids[:10]"
      ],
      "metadata": {
        "id": "cVV8p3yJQGcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds"
      ],
      "metadata": {
        "id": "J5diOABqQI7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 15\n",
        "\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "metadata": {
        "id": "Mus9IsBhQLoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix.shape"
      ],
      "metadata": {
        "id": "E0yNbw18QOVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U.shape"
      ],
      "metadata": {
        "id": "nPEO6WXJQQvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sigma = np.diag(sigma)\n",
        "sigma.shape"
      ],
      "metadata": {
        "id": "WxXj5CD6QUpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vt.shape"
      ],
      "metadata": {
        "id": "-jL5joTMQWak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It was generated predictions for items the user have not yet interaction, which we will exploit for recommendations.\n",
        "\n"
      ],
      "metadata": {
        "id": "OnJXRmfwQaPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "all_user_predicted_ratings"
      ],
      "metadata": {
        "id": "oTP8G4m8QbBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings.shape"
      ],
      "metadata": {
        "id": "9JY-Bv6-QeN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\n",
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
        "cf_preds_df.head()"
      ],
      "metadata": {
        "id": "YPfvDljqQg6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "metadata": {
        "id": "PFCEsISTQjei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global books\n",
        "books.head()"
      ],
      "metadata": {
        "id": "Za70KiMuQmQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFRecommender:\n",
        "\n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "\n",
        "    def __init__(self, cf_predictions_df):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'recStrength'})\n",
        "\n",
        "        # Recommend the highest predicted rating content that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['ISBN'].isin(items_to_ignore)].sort_values('recStrength', ascending = False).head(topn)\n",
        "        recommendations_df=recommendations_df.merge(books,on='ISBN',how='inner')\n",
        "        recommendations_df=recommendations_df[['ISBN','Book-Title','recStrength']]\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "\n",
        "\n",
        "cf_recommender_model = CFRecommender(cf_preds_df)"
      ],
      "metadata": {
        "id": "UHpaMeLpQooA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexing by personId to speed up the searches during evaluation\n",
        "interactions_full_indexed_df = interactions_full_df.set_index('User-ID')\n",
        "interactions_train_indexed_df = interactions_train_df.set_index('User-ID')\n",
        "interactions_test_indexed_df = interactions_test_df.set_index('User-ID')"
      ],
      "metadata": {
        "id": "okQEp5-hQs4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_items_interacted(UserID, interactions_df):\n",
        "    interacted_items = interactions_df.loc[UserID]['ISBN']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "metadata": {
        "id": "cBKyVGCSQu_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelRecommender:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, UserID, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(UserID, interactions_full_indexed_df)\n",
        "        all_items = set(ratings_explicit['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['ISBN'])])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df),topn=10000000000)\n",
        "        print('Recommendation for User-ID = ',person_id)\n",
        "        print(person_recs_df.head(10))\n",
        "\n",
        "        # Function to evaluate the performance of model at overall level\n",
        "    def recommend_book(self, model ,userid):\n",
        "\n",
        "        person_metrics = self.evaluate_model_for_user(model, userid)\n",
        "        return\n",
        "\n",
        "model_recommender = ModelRecommender()"
      ],
      "metadata": {
        "id": "QSnaAopiQyH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's recommend books to User-Id 69078 and see the results."
      ],
      "metadata": {
        "id": "3qZ3qm1mQ6OY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(interactions_full_indexed_df.index.values))"
      ],
      "metadata": {
        "id": "qkT3-Y3TQ2eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user=int(input(\"Enter User ID from above list for book recommendation  \"))\n",
        "model_recommender.recommend_book(cf_recommender_model,user)"
      ],
      "metadata": {
        "id": "f_u8sdU8Q95l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "W3bdM6_4RElV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Recommender Systems, there are a set metrics commonly used for evaluation. We choose to work with Top-N accuracy metrics, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.\n",
        "\n",
        "This evaluation method works as follows:\n",
        "For each user\n",
        "\n",
        "For each item the user has interacted in test set\n",
        "\n",
        "Sample 100 other items the user has never interacted.\n",
        "\n",
        "Ask the recommender model to produce a ranked list of recommended items, from a set composed of one interacted item and the 100 non-interacted items\n",
        "\n",
        "Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\n",
        "\n",
        "Aggregate the global Top-N accuracy metrics\n"
      ],
      "metadata": {
        "id": "szWWHv5tRGUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, UserID, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(UserID, interactions_full_indexed_df)\n",
        "        all_items = set(ratings_explicit['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['ISBN'])])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, seed=item_id)    #%(2**32))\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        person_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return person_metrics\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
        "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
        "            person_metrics['User-ID'] = person_id\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('%d users processed' % idx)\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator()"
      ],
      "metadata": {
        "id": "aTFIbX7gRAHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "\n",
        "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
        "cf_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "Kb0uAeHGRalC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "1. In EDA, the Top-10 most rated books were essentially novels. Books like The Lovely Bone and The Secret Life of Bees were very well perceived.\n",
        "2.Majority of the readers were of the age bracket 20-35 and most of them came from North American and European countries namely USA, Canada, UK, Germany and Spain.\n",
        "\n",
        "3.If we look at the ratings distribution, most of the books have high ratings with maximum books being rated 8. Ratings below 5 are few in number.\n",
        "\n",
        "4.Author with the most books was Agatha Christie, William Shakespeare and Stephen King.\n",
        "\n",
        "5.For modelling, it was observed that for model based collaborative filtering SVD technique worked way better than NMF with lower Mean Absolute Error (MAE) .\n",
        "\n",
        "6.Amongst the memory based approach, item-item CF performed better than user-user CF because of lower computation .\n"
      ],
      "metadata": {
        "id": "sstYDpJJRg_w"
      }
    }
  ]
}